{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04bd1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from farasa.segmenter import FarasaSegmenter\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import torch\n",
    "\n",
    "# Load and prepare dataset\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "df = df.rename(columns={\"Comment\": \"text\", \"Toxicity\": \"label\"}) \n",
    "df[\"label\"] = df[\"label\"].astype(int)\n",
    "\n",
    "# Farasa segmentation \n",
    "farasa_segmenter = FarasaSegmenter(interactive=True)\n",
    "\n",
    "def farasa_tokenize(example):\n",
    "    segmented = farasa_segmenter.segment(example[\"text\"])\n",
    "    return {\"text\": segmented}\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.map(farasa_tokenize)\n",
    "\n",
    "# Train/test split\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = dataset['train']\n",
    "eval_dataset = dataset['test']\n",
    "\n",
    "# Load MARBERTv2\n",
    "model_name = \"UBC-NLP/MARBERTv2\"\n",
    "hf_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Tokenization \n",
    "def tokenize_function(examples):\n",
    "    return hf_tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval = eval_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Metrics\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return accuracy.compute(predictions=preds, references=p.label_ids)\n",
    "\n",
    "# TrainingArguments \n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    #evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-5,\n",
    "    #load_best_model_at_end=True,\n",
    "    logging_dir='./logs',\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")\n",
    "\n",
    "# Trainer \n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    tokenizer=hf_tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()\n",
    "\n",
    "# LIME Explanation\n",
    "\n",
    "# Prediction function for LIME\n",
    "class_names = ['Non-Toxic', 'Toxic']\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "def predict_proba(texts):\n",
    "    inputs = hf_tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}  \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# Take a sample sentence\n",
    "sample_text = df['text'].iloc[0]\n",
    "print(\"Sample text:\", sample_text)\n",
    "\n",
    "# LIME explanation\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "explanation = explainer.explain_instance(sample_text, predict_proba, num_features=10)\n",
    "explanation.show_in_notebook(text=sample_text)  \n",
    "\n",
    "for feature, weight in explanation.as_list():\n",
    "    print(f\"{feature}: {weight:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
